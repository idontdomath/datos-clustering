{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('default') # haciendo los graficos un poco mas bonitos en matplotlib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# 3d plotting of the iris set for this examples\n",
    "def plot_iris_clustering(fignum, X, y, title, label_names=None):\n",
    "    fig = plt.figure(fignum, figsize=(8, 6))\n",
    "    ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "\n",
    "    if label_names is not None:\n",
    "        for name, label in label_names:\n",
    "            ax.text3D(X[y == label, 3].mean(),\n",
    "                      X[y == label, 0].mean(),\n",
    "                      X[y == label, 2].mean() + 2, name,\n",
    "                      horizontalalignment='center',\n",
    "                      bbox=dict(alpha=.2, edgecolor='w', facecolor='w'))\n",
    "    # Reorder the labels to have colors matching the cluster results\n",
    "    y = np.choose(y, [1, 2, 0]).astype(np.float)\n",
    "    ax.scatter(X[:, 3], X[:, 0], X[:, 2], c=y, edgecolor='k')\n",
    "\n",
    "    ax.w_xaxis.set_ticklabels([])\n",
    "    ax.w_yaxis.set_ticklabels([])\n",
    "    ax.w_zaxis.set_ticklabels([])\n",
    "    ax.set_xlabel('Petal width')\n",
    "    ax.set_ylabel('Sepal length')\n",
    "    ax.set_zlabel('Petal length')\n",
    "    ax.set_title(title)\n",
    "    ax.dist = 12\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dendrogram plotting\n",
    "# source: https://github.com/scikit-learn/scikit-learn/blob/70cf4a676caa2d2dad2e3f6e4478d64bcb0506f7/examples/cluster/plot_hierarchical_clustering_dendrogram.py\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "   \n",
    "    # Children of hierarchical clustering\n",
    "    children = model.children_\n",
    "\n",
    "    # Distances between each pair of children\n",
    "    # Since we don't have this information, we can use a uniform one for plotting\n",
    "    distance = np.arange(children.shape[0])\n",
    "\n",
    "    # The number of observations contained in each cluster level\n",
    "    no_of_observations = np.arange(2, children.shape[0]+2)\n",
    "\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "    linkage_matrix = np.column_stack([children, distance, no_of_observations]).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Jerarquico\n",
    "\n",
    "Clustering Jerarquico corresponde a una familia general de algoritmos de clustering que construyen clusters anidados a partir de mergear y realizar el split de ellos sucesivamente. Esta jerarquia de clusters puede representarse en un arbol (o dendrograma). La raiz del arbol es el cluster unico que unifica todo las muestras, siendo las horas clusters con solamente una muestra del set de datos.\n",
    "\n",
    "## Carga Inicial del Set de Datos Iris\n",
    "\n",
    "Utilizamos el set de datos iris ya utilizado en otras oportunidades, el cual tiene 3 dimensiones y tenemos para cada uno de los puntos, una categoria especifica que usaremos como control.\n",
    "\n",
    "El objetivo que tendremos en general con es sin conocer los labels, intentar recuperar los clusters utilizando el algoritmo de clustering jerarquico.\n",
    "\n",
    "En la visualizacion de abajo se ve en 3 dimensiones, cada uno de los puntos del set de datos de Iris y a que categoria pertenece cada uno de esos puntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "x = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "\n",
    "fignum = 1\n",
    "\n",
    "X = x\n",
    "y = iris.target\n",
    "label_names = [('Setosa', 0),\n",
    "               ('Versicolour', 1),\n",
    "               ('Virginica', 2)]\n",
    "\n",
    "plot_iris_clustering(fignum, X, y, \"Iris: Original Set with Labels\", label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando y Visualizando los resultados del Clustering Jerarquico\n",
    "\n",
    "El objeto AgglomerativeClustering de sklearn realiza el clustering jerarquico usando un enfoque bottom-up: cada observacion comienza el algoritmo en su propio cluster, y sucesivamente los distintos clusters son mergeados entre si. La propiedad 'linkeage' es la utilizada para definir el criterio a partir del cual se realiza el merge implementando las siguientes opciones:\n",
    "\n",
    "- **Ward** minimizes the sum of squared differences within all clusters. It is a variance-minimizing approach and in this sense is similar to the k-means objective function but tackled with an agglomerative hierarchical approach.\n",
    "- **Maximum or complete linkage** minimizes the maximum distance between observations of pairs of clusters.\n",
    "- **Average linkage** minimizes the average of the distances between all observations of pairs of clusters.\n",
    "- **Single linkage** minimizes the distance between the closest observations of pairs of clusters.\n",
    "\n",
    "![Linkage](hierarchical-linkage.png)\n",
    "\n",
    "Mas informacion en:\n",
    "\n",
    "- http://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering\n",
    "- http://scikit-learn.org/stable/auto_examples/cluster/plot_digits_linkage.html#sphx-glr-auto-examples-cluster-plot-digits-linkage-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iris_agglomerative_clustering(linkage='ward'):\n",
    "    \n",
    "    fignum = 1\n",
    "\n",
    "    iris = datasets.load_iris()\n",
    "    x = iris.data\n",
    "\n",
    "    model = AgglomerativeClustering(n_clusters=3, linkage=linkage)\n",
    "    model = model.fit(x)\n",
    "    X = x\n",
    "    y = model.labels_\n",
    "    plot_iris_clustering(fignum, X, y, \"Hierarchical Clustering: %s linkage\" % linkage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dendrograma\n",
    "\n",
    "A partir de la siguiente implementacion podemos obtener el dendrograma luego de realizar aplicar clustering jerarquico en nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limitamos la cantidad de datos para poder representarlo\n",
    "x = iris.data[:25]\n",
    "model = AgglomerativeClustering(n_clusters=3)\n",
    "\n",
    "model = model.fit(x)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plot_dendrogram(model, labels=model.labels_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_iris_clustering(1, x, model.labels_, \"Hierarchical Clustering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Jerarquico: Ward Linkeage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_agglomerative_clustering(linkage='ward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Jerarquico: Complete Linkeage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_agglomerative_clustering(linkage='complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Jerarquico: Average Linkeage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_agglomerative_clustering(linkage='average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Jerarquico: Single Linkeage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_agglomerative_clustering(linkage='single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
